{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cudf \n",
    "import cuml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data description, and the data that this example uses are available at \n",
    "[the UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "data_dir = '../../data/bike/'\n",
    "if not os.path.exists(data_dir):\n",
    "    print('creating bike data directory')\n",
    "    os.system('mkdir ../../data/bike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00275/'\n",
    "fn = 'Bike-Sharing-Dataset.zip'\n",
    "if not os.path.isfile(data_dir+fn):\n",
    "        print(f'Downloading {base_url+fn} to {data_dir+fn}')\n",
    "        urllib.request.urlretrieve(base_url+fn, data_dir+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile \n",
    "files = []\n",
    "with ZipFile(data_dir+fn) as myzip:\n",
    "    files = myzip.namelist()\n",
    "    print(\"Files extracted: \"+ str(files))\n",
    "    myzip.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Description: \n",
    "#         \n",
    "#         - instant: record index\n",
    "#         - dteday : date\n",
    "#         - season : season (1:springer, 2:summer, 3:fall, 4:winter)\n",
    "#         - yr : year (0: 2011, 1:2012)\n",
    "#         - mnth : month ( 1 to 12)\n",
    "#         - hr : hour (0 to 23)\n",
    "#         - holiday : weather day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule)\n",
    "#         - weekday : day of the week\n",
    "#         - workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n",
    "#         + weathersit : \n",
    "#                 - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "#                 - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "#                 - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "#                 - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "#         - temp : Normalized temperature in Celsius. The values are divided to 41 (max)\n",
    "#         - atemp: Normalized feeling temperature in Celsius. The values are divided to 50 (max)\n",
    "#         - hum: Normalized humidity. The values are divided to 100 (max)\n",
    "#         - This is a good example of variables we might not have a good theoretical intuation around\n",
    "#         - windspeed: Normalized wind speed. The values are divided to 67 (max)\n",
    "#         - casual: count of casual users\n",
    "#         - registered: count of registered users\n",
    "#         - cnt: count of total rental bikes including both casual and registered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use `files[2]` and read in the hour.csv dataset.  Valid datasets are `files[1]` (day.csv) and `files[2]` (hour.csv).   Please do not use `files[0]`, which is a README file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = cudf.read_csv(data_dir+files[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the index, the timestamp (because they have broken it down for us), \n",
    "and the individual counts that make up our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['instant', 'dteday', 'casual', 'registered']\n",
    "gdf = gdf.drop(drop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to create one-hot encoded variables, also known as dummy variables, for each of the time variables as well as the weather situation. We're going to drop one of each of these dummy variables so we don't create colinearity. \n",
    "\n",
    "The next data munging step we take is to convert all of our data into the same type, because that is what the cuML algorithms are expecting. \n",
    "\n",
    "Last, we split our data into test and train sets, training on 2011 data, and testing on 2012. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_list = ['season','yr', 'mnth', 'hr', 'weekday', 'weathersit']\n",
    "\n",
    "for item in dummies_list:\n",
    "    codes = gdf[item].unique()\n",
    "    gdf = gdf.one_hot_encoding(item, '{}_dummy'.format(item), codes)\n",
    "    gdf = gdf.drop('{}_dummy_1'.format(item))\n",
    "\n",
    "#cuML current requires all data be of the same type, so this loop converts all values into floats\n",
    "for col in gdf.columns.tolist():\n",
    "    gdf[col] = gdf[col].astype('float32')\n",
    "    \n",
    "test = gdf.query('yr == 1').drop(dummies_list)\n",
    "train = gdf.query('yr == 0').drop(dummies_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to test out how well a small variable does against all the variables available. I select \"weathersit_dummy_4\" because as we see above, that seems like the worst weather for bike riding. Also, based on personal experience, bike riding in high wind is not fun either. I add workday because I'm sure it has some impact, but I'm not sure what. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['cnt']\n",
    "y_test = test['cnt']\n",
    "\n",
    "#Some of the variables, chosen by theory\n",
    "X_train_1 = train[['weathersit_dummy_4', 'windspeed', 'workingday']]\n",
    "X_test_1 = test[['weathersit_dummy_4', 'windspeed', 'workingday']]\n",
    "\n",
    "#all of the varibles.\n",
    "X_train_2 = train.drop('cnt')\n",
    "X_test_2 = test.drop('cnt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I run two regressions. The first is based on small set of variable I think will be most impactful to bike ridership. The second regression inclueds all the variables availale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS_1 = cuml.LinearRegression()\n",
    "fit_1 = OLS_1.fit(X_train_1, y_train)\n",
    "y_hat_1 = fit_1.predict(X_test_1)\n",
    "MSE_1 = ((y_test - y_hat_1)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS_2 = cuml.LinearRegression()\n",
    "fit_2 = OLS_2.fit(X_train_2, y_train)\n",
    "y_hat_2 = fit_2.predict(X_test_2)\n",
    "MSE_2 = ((y_test - y_hat_2)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {'MSE_OLS_THEORY':MSE_1,\n",
    "         'MSE_OLS_ALL': MSE_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like I was wrong, and the model with everything performs better on the out-of-sample data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE_OLS_THEORY:     {}'.format(MSE_1))\n",
    "print('MSE_OLS_EVERYTHING: {}'.format(MSE_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"everything\" model outperformed the small model, but let's see if we can do better by doing a Ridge regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do a small hyperparameter search for alpha, checking 100 different values. This is fast to do with RAPIDS. Also notice that I am appending the results of each Ridge model onto the dictionary containing our earlier results, so I can more easily see which model is the best at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in np.arange(0.01, 1, 0.01): #alpha value has to be positive\n",
    "    \n",
    "    Ridge = cuml.Ridge(alpha=alpha, fit_intercept=True)\n",
    "    fit_3 = Ridge.fit(X_train_2, y_train)\n",
    "    y_hat_3 = fit_3.predict(X_test_2)\n",
    "    MSE_3 = ((y_test - y_hat_3)**2).sum()\n",
    "    output['MSE_RIDGE_{}'.format(alpha)] = MSE_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that our regulaized model does better than the rest, include OLS with all the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min MSE: {}'.format(min(output, key=output.get)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can uncomment the code below to see all 100 model MSEs\n",
    "#Notice in particular that MSE for OLS with everything and Ridge with alpha = 0 are essentially the same. \n",
    "import pprint\n",
    "pprint.pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
