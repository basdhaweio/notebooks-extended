{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Louvain-Colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hogs0w_kXBs8",
        "colab_type": "text"
      },
      "source": [
        "#Setup:\n",
        "\n",
        "1. Use pynvml to confirm Colab allocated you a Tesla T4 GPU.\n",
        "2. Install most recent Miniconda release compatible with Google Colab's Python install  (3.6.7)\n",
        "3. Install RAPIDS libraries\n",
        "4. Copy RAPIDS .so files into current working directory, a workaround for conda/colab interactions\n",
        "5. Add the ngrok binary to expose Dask's status dashboard\n",
        "6. Update env variables so Python can find and use RAPIDS artifacts\n",
        "​\n",
        "All of the above steps are automated in the next cell.\n",
        "​\n",
        "You should re-run this cell any time your instance re-starts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGPaw1dGMEEo",
        "colab_type": "code",
        "outputId": "9dfcbc32-4c8a-4fe2-e8fa-28bdee3b461c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1728
        }
      },
      "source": [
        "\n",
        "!wget https://github.com/randerzander/notebooks-extended/raw/master/utils/rapids-colab.sh\n",
        "!chmod +x rapids-colab.sh\n",
        "!./rapids-colab.sh\n",
        "\n",
        "import sys, os\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
        "\n",
        "import nvstrings, nvcategory, cudf, cuml, xgboost\n",
        "import dask_cudf, dask_cuml, dask_xgboost\n",
        "from dask.distributed import Client, LocalCluster, wait, progress\n",
        "\n",
        "# we have one GPU, so limit Dask's workers and threads to exactly 1\n",
        "cluster = LocalCluster(processes=False, threads_per_worker=1, n_workers=1)\n",
        "client = Client(cluster)\n",
        "client"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-06 16:52:25--  https://github.com/randerzander/notebooks-extended/raw/master/utils/rapids-colab.sh\n",
            "Resolving github.com (github.com)... 52.69.186.44\n",
            "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/randerzander/notebooks-extended/master/utils/rapids-colab.sh [following]\n",
            "--2019-06-06 16:52:30--  https://raw.githubusercontent.com/randerzander/notebooks-extended/master/utils/rapids-colab.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1746 (1.7K) [text/plain]\n",
            "Saving to: ‘rapids-colab.sh’\n",
            "\n",
            "rapids-colab.sh     100%[===================>]   1.71K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-06 16:52:31 (228 MB/s) - ‘rapids-colab.sh’ saved [1746/1746]\n",
            "\n",
            "--2019-06-06 16:52:33--  https://github.com/randerzander/notebooks-extended/raw/master/utils/env-check.py\n",
            "Resolving github.com (github.com)... 52.69.186.44\n",
            "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/randerzander/notebooks-extended/master/utils/env-check.py [following]\n",
            "--2019-06-06 16:52:33--  https://raw.githubusercontent.com/randerzander/notebooks-extended/master/utils/env-check.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 433 [text/plain]\n",
            "Saving to: ‘env-check.py’\n",
            "\n",
            "env-check.py        100%[===================>]     433  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-06 16:52:33 (14.4 MB/s) - ‘env-check.py’ saved [433/433]\n",
            "\n",
            "Checking for GPU type:\n",
            "Woo! You got the right kind of GPU!\n",
            "Removing existing dask & xgboost packages\n",
            "Uninstalling xgboost-0.90:\n",
            "  Successfully uninstalled xgboost-0.90\n",
            "Uninstalling dask-1.1.5:\n",
            "  Successfully uninstalled dask-1.1.5\n",
            "Uninstalling distributed-1.25.3:\n",
            "  Successfully uninstalled distributed-1.25.3\n",
            "\u001b[33mWARNING: Skipping dask-xgboost as it is not installed.\u001b[0m\n",
            "Installing conda\n",
            "--2019-06-06 16:52:38--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-4.5.4-Li 100%[===================>]  55.76M   200MB/s    in 0.3s    \n",
            "\n",
            "2019-06-06 16:52:39 (200 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "Python 3.6.5 :: Anaconda, Inc.\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Installing RAPIDS packages\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oriNkCjHRXP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Louvain Community Detection\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The Louvain method of community detection is a greedy hierarchical clustering algorithm which seeks to optimize modularity as it progresses. Louvain starts with each vertex in its own clusters and iteratively merges groups using graph contraction.\n",
        "\n",
        "For a detailed description of the algorithm see: [https://en.wikipedia.org/wiki/Louvain_Modularity](https://en.wikipedia.org/wiki/Louvain_Modularity).\n",
        "\n",
        "It takes as input a cugraph.Graph object and returns as output a cudf.Datafrome object with the id and assigned partition for each vertex as well as the final modularity score.\n",
        "\n",
        "To comoute the Louvain cluster in cuGraph use: \n",
        "\n",
        "__nvLouvain(G)__\n",
        "* __G__: A `cugraph.Graph` object\n",
        "\n",
        "Returns: \n",
        "* tupal lovain dataframe and modularity\n",
        "* __louvain__: `cudf.DataFrame` with two named columns: \n",
        "    * `louvain[\"vertex\"]`: The vertex id.\n",
        "    * `louvain[\"partition\"]`: The assigned partition.\n",
        "* __modularity__ : the overall modularity of the graph\n",
        "\n",
        "All vertices with the same partition ID are in the same cluster.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzFMitZZKbBe",
        "colab_type": "text"
      },
      "source": [
        "### Test Data\n",
        "We will be using the Zachary Karate club dataset \n",
        "*W. W. Zachary, An information flow model for conflict and fission in small groups, Journal of\n",
        "Anthropological Research 33, 452-473 (1977).*\n",
        "\n",
        "![Karate Club](https://raw.githubusercontent.com/rapidsai/notebooks/branch-0.8/cugraph/img/zachary_black_lines.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQrYFLcBMo5W",
        "colab_type": "text"
      },
      "source": [
        "### Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klOERCvnGEgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import needed libraries\n",
        "import cugraph\n",
        "import numpy as np\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2XR7Qx2NNdj",
        "colab_type": "text"
      },
      "source": [
        "## Reading data using cuDF\n",
        "\n",
        "**At the creation of this notebook, `dask_cudf` doesn't work with `cugraph`, so we have to use `cudf`.**  A future repo, `dask_cugraph`, will have dask compatibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR6V3JXuGQzY",
        "colab_type": "code",
        "outputId": "2dd4eff5-5a54-49f8-d7c7-2c602dc957bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "import cudf\n",
        "# Save test file\n",
        "datafile='https://raw.githubusercontent.com/rapidsai/notebooks/branch-0.8/cugraph/data/karate-data.csv'\n",
        "\n",
        "# Read the data file\n",
        "cols = [\"src\", \"dst\"]\n",
        "\n",
        "dtypes = OrderedDict([\n",
        "        (\"src\", \"int32\"), \n",
        "        (\"dst\", \"int32\")\n",
        "        ])\n",
        "\n",
        "df = pd.read_csv(datafile, names=cols, delimiter='\\t', dtype=list(dtypes.values()) )\n",
        "gdf = cudf.from_pandas(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-d4dbebdaca3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         ])\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/io/csv.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, lineterminator, quotechar, quoting, doublequote, header, mangle_dupe_cols, usecols, sep, delimiter, delim_whitespace, skipinitialspace, names, dtype, skipfooter, skiprows, dayfirst, compression, thousands, decimal, true_values, false_values, nrows, byte_range, skip_blank_lines, comment, na_values, keep_default_na, na_filter, prefix, index_col)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mna_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_filter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     )\n",
            "\u001b[0;32mcudf/bindings/csv.pyx\u001b[0m in \u001b[0;36mcudf.bindings.csv.cpp_read_csv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcudf/bindings/csv.pyx\u001b[0m in \u001b[0;36mcudf.bindings.csv.cpp_read_csv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWVQxKzLNPSm",
        "colab_type": "code",
        "outputId": "13a9a69e-d0ca-4410-eb40-43f3d7560800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# Save test file\n",
        "!wget https://raw.githubusercontent.com/rapidsai/notebooks/branch-0.8/cugraph/data/karate-data.csv\n",
        "datafile='karate-data.csv'\n",
        "\n",
        "# Read the data file\n",
        "cols = [\"src\", \"dst\"]\n",
        "\n",
        "dtypes = OrderedDict([\n",
        "        (\"src\", \"int32\"), \n",
        "        (\"dst\", \"int32\")\n",
        "        ])\n",
        "\n",
        "gdf = cudf.read_csv(datafile, names=cols, delimiter='\\t', dtype=list(dtypes.values()) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-04 20:08:07--  https://raw.githubusercontent.com/rapidsai/notebooks/branch-0.8/cugraph/data/karate-data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 814 [text/plain]\n",
            "Saving to: ‘karate-data.csv’\n",
            "\n",
            "\rkarate-data.csv       0%[                    ]       0  --.-KB/s               \rkarate-data.csv     100%[===================>]     814  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-04 20:08:07 (196 MB/s) - ‘karate-data.csv’ saved [814/814]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFrh4wqmOcGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Louvain is dependent on vertex ID starting at zero\n",
        "gdf[\"src_0\"] = gdf[\"src\"] - 1\n",
        "gdf[\"dst_0\"] = gdf[\"dst\"] - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AgNOVJXNtB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The algorithm also requires that there are vertex weights.  Just use 1.0 \n",
        "gdf[\"data\"] = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0T6XQtbOfPj",
        "colab_type": "code",
        "outputId": "263c47fb-b703-49f9-be28-ba106af3327c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# just for fun, let's look at the data types in the dataframe\n",
        "gdf.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "src        int32\n",
              "dst        int32\n",
              "src_0      int32\n",
              "dst_0      int32\n",
              "data     float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJZSEVBWHCSZ",
        "colab_type": "code",
        "outputId": "047e0ef5-251e-4d0c-b124-de9c4aef311d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print(gdf.head(5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   src  dst  src_0  dst_0  data\n",
            "0    1    2      0      1   1.0\n",
            "1    1    3      0      2   1.0\n",
            "2    1    4      0      3   1.0\n",
            "3    1    5      0      4   1.0\n",
            "4    1    6      0      5   1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alxcYj8QIQno",
        "colab_type": "code",
        "outputId": "b09f1011-10b1-4e92-9191-f878028c450e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "gdf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div><strong>Dask DataFrame Structure:</strong></div>\n",
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>dst</th>\n",
              "      <th>src_0</th>\n",
              "      <th>dst_0</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>npartitions=1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>int32</td>\n",
              "      <td>int32</td>\n",
              "      <td>int32</td>\n",
              "      <td>int32</td>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "<div>Dask Name: assign, 10 tasks</div>"
            ],
            "text/plain": [
              "<dask_cudf.DataFrame | 10 tasks | 1 npartitions>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMIqYrTGOhZN",
        "colab_type": "code",
        "outputId": "c0f246f7-2cbe-4365-ad75-b38c613c068d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "# create a Graph \n",
        "G = cugraph.Graph()\n",
        "G.add_edge_list(gdf[\"src_0\"], gdf[\"dst_0\"], gdf[\"data\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute '_column'"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: 'cugraph.get_gdf_column_view'\n",
            "AttributeError: 'Series' object has no attribute '_column'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute '_column'"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: 'cugraph.get_gdf_column_view'\n",
            "AttributeError: 'Series' object has no attribute '_column'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute '_column'"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: 'cugraph.get_gdf_column_view'\n",
            "AttributeError: 'Series' object has no attribute '_column'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "GDFError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mGDFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-230009ebd839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcugraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"src_0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dst_0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32mcugraph/graph/c_graph.pyx\u001b[0m in \u001b[0;36mcugraph.Graph.add_edge_list\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcudf/bindings/cudf_cpp.pyx\u001b[0m in \u001b[0;36mcudf.bindings.cudf_cpp.check_gdf_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcudf/bindings/cudf_cpp.pyx\u001b[0m in \u001b[0;36mcudf.bindings.cudf_cpp.check_gdf_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mGDFError\u001b[0m: b'GDF_UNSUPPORTED_DTYPE'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wwaVNjxOjCq",
        "colab_type": "code",
        "outputId": "8308fef7-9405-419b-f73e-0800688024c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "# Call Louvain on the graph\n",
        "df, mod = cugraph.nvLouvain(G)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "GDFError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mGDFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-40b1a72443e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcugraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvLouvain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32mcugraph/louvain/louvain_wrapper.pyx\u001b[0m in \u001b[0;36mcugraph.nvLouvain\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcugraph/louvain/louvain_wrapper.pyx\u001b[0m in \u001b[0;36mcugraph.nvLouvain\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcudf/bindings/cudf_cpp.pyx\u001b[0m in \u001b[0;36mcudf.bindings.cudf_cpp.check_gdf_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcudf/bindings/cudf_cpp.pyx\u001b[0m in \u001b[0;36mcudf.bindings.cudf_cpp.check_gdf_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mGDFError\u001b[0m: b'GDF_INVALID_API_CALL'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDPqamqwOlNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the modularity score\n",
        "print('Modularity was {}'.format(mod))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juOmJhBBcJr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa9k30GbcLeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How many partitions where found\n",
        "part_ids = df[\"partition\"].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXlCF5DgcNDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(str(len(part_ids)) + \" partition(s) detected\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPZpCWgIcPBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for p in range(len(part_ids)):\n",
        "    part = []\n",
        "    for i in range(len(df)):\n",
        "        if (df['partition'][i] == p):\n",
        "            part.append(df['vertex'][i] +1)\n",
        "    print(\"Partition \" + str(p) + \":\")\n",
        "    print(part)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHHwqhN_cZh2",
        "colab_type": "text"
      },
      "source": [
        "# Next Steps #\n",
        "\n",
        "For an overview of how you can access and work with your own datasets in Colab, check out [this guide](https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92).\n",
        "\n",
        "For more RAPIDS examples, check out our RAPIDS notebooks repos:\n",
        "1. https://github.com/rapidsai/notebooks\n",
        "2. https://github.com/rapidsai/notebooks-extended"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIxYrZXxcaft",
        "colab_type": "text"
      },
      "source": [
        "Copyright (c) 2019, NVIDIA CORPORATION.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    }
  ]
}